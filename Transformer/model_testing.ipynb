{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model import *\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "    \n",
    "#RNN model with LSTM which takes input and embedds it to a certain dimension and then passes it through the LSTM layer and then the output is passed through a fully connected layer to get the final output\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.device = 'cpu'\n",
    "        # self.embedding = nn.Embedding(65536, input_size)\n",
    "        # self.pe = PositionalEncoding(input_size)\n",
    "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout = 0.2)\n",
    "        self.fc = nn.Sequential(nn.Linear(hidden_size, num_classes), nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(self.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(self.device)\n",
    "        # x = self.embedding(x)\n",
    "        # x = self.pe(x)\n",
    "        x = torch.nn.functional.one_hot(x.to(torch.int64), num_classes=2).float()\n",
    "        out, _ = self.rnn(x, (h0, c0))\n",
    "        # out = out[:, -1, :]\n",
    "        out = torch.mean(out, 1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "transformer = RNN(input_size = 2, hidden_size = 1024, num_layers = 2, num_classes = 7).to('cpu')\n",
    "criterion = nn.BCELoss().to('cpu')\n",
    "optimizer = torch.optim.Adam(transformer.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the data\n",
    "load_lstm = False\n",
    "\n",
    "split_ratio = 0.8\n",
    "val_ratio = 0.2\n",
    "data = pd.read_csv(\"Data/dataset_512.csv\", dtype = str)\n",
    "train_df = data.sample(frac = split_ratio)\n",
    "test_df = data.drop(train_df.index)\n",
    "val_df = train_df.sample(frac = val_ratio)\n",
    "train_df = train_df.drop(val_df.index)\n",
    "\n",
    "train_dataset = QueueDataset_LSTM(train_df) if load_lstm else QueueDataset(train_df)\n",
    "test_dataset = QueueDataset_LSTM(test_df) if load_lstm else QueueDataset(test_df)\n",
    "val_dataset = QueueDataset_LSTM(val_df) if load_lstm else QueueDataset(val_df)\n",
    "\n",
    "#initialize the data loader \n",
    "train_loader_512 = DataLoader(train_dataset, batch_size = 128, shuffle = True)\n",
    "test_loader_512 = DataLoader(test_dataset, batch_size = 128, shuffle = True)\n",
    "val_loader_512 = DataLoader(val_dataset, batch_size = 128, shuffle = True)\n",
    "\n",
    "data = pd.read_csv(\"Data/dataset_1024.csv\", dtype = str)\n",
    "train_df = data.sample(frac = split_ratio)\n",
    "test_df = data.drop(train_df.index)\n",
    "val_df = train_df.sample(frac = val_ratio)\n",
    "train_df = train_df.drop(val_df.index)\n",
    "\n",
    "train_dataset = QueueDataset_LSTM(train_df) if load_lstm else QueueDataset(train_df)\n",
    "test_dataset = QueueDataset_LSTM(test_df) if load_lstm else QueueDataset(test_df)\n",
    "val_dataset = QueueDataset_LSTM(val_df) if load_lstm else QueueDataset(val_df)\n",
    "\n",
    "train_loader_1024 = DataLoader(train_dataset, batch_size = 128, shuffle = True)\n",
    "test_loader_1024 = DataLoader(test_dataset, batch_size = 128, shuffle = True)\n",
    "val_loader_1024 = DataLoader(val_dataset, batch_size = 128, shuffle = True)\n",
    "\n",
    "data = pd.read_csv(\"Data/dataset_2048.csv\", dtype = str)\n",
    "train_df = data.sample(frac = split_ratio)\n",
    "test_df = data.drop(train_df.index)\n",
    "val_df = train_df.sample(frac = val_ratio)\n",
    "train_df = train_df.drop(val_df.index)\n",
    "\n",
    "train_dataset = QueueDataset_LSTM(train_df) if load_lstm else QueueDataset(train_df)\n",
    "test_dataset = QueueDataset_LSTM(test_df) if load_lstm else QueueDataset(test_df)\n",
    "val_dataset = QueueDataset_LSTM(val_df) if load_lstm else QueueDataset(val_df)\n",
    "\n",
    "train_loader_2048 = DataLoader(train_dataset, batch_size = 128, shuffle = True)\n",
    "test_loader_2048 = DataLoader(test_dataset, batch_size = 128, shuffle = True)\n",
    "val_loader_2048 = DataLoader(val_dataset, batch_size = 128, shuffle = True)\n",
    "\n",
    "# data = pd.read_csv(\"Data/dataset_4096.csv\", dtype = str)\n",
    "# train_df = data.sample(frac = split_ratio)\n",
    "# test_df = data.drop(train_df.index)\n",
    "# val_df = train_df.sample(frac = val_ratio)\n",
    "# train_df = train_df.drop(val_df.index)\n",
    "\n",
    "# train_dataset = QueueDataset_LSTM(train_df) if load_lstm else QueueDataset(train_df)\n",
    "# test_dataset = QueueDataset_LSTM(test_df) if load_lstm else QueueDataset(test_df)\n",
    "# val_dataset = QueueDataset_LSTM(val_df) if load_lstm else QueueDataset(val_df)\n",
    "\n",
    "# train_loader_4096 = DataLoader(train_dataset, batch_size = 128, shuffle = True)\n",
    "# test_loader_4096 = DataLoader(test_dataset, batch_size = 128, shuffle = True)\n",
    "# val_loader_4096 = DataLoader(val_dataset, batch_size = 128, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model hyperparameters \n",
    "ntokens = 256  # size of vocabulary\n",
    "emsize = 192  # embedding dimension\n",
    "d_hid = 192  # dimension of the feedforward network model in ``nn.TransformerEncoder``\n",
    "nlayers = 1  # number of ``nn.TransformerEncoderLayer`` in ``nn.TransformerEncoder``\n",
    "nhead = 1 # number of heads in ``nn.MultiheadAttention``\n",
    "dropout = 0.05  # dropout probability\n",
    "threshold = 0.5\n",
    "device = \"cuda\"\n",
    "torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "transformer = RandomLM(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)\n",
    "criterion = nn.BCELoss().to(device)\n",
    "optimizer = torch.optim.Adam(transformer.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN 512\n",
      "epoch: 1, batch: 100, train loss: 0.280, train macro: 0.892, train micro: 0.902, train sample: 0.799, train weighted 0.903, val loss: 0.263, val macro: 0.895, val micro: 0.903 val sample: 0.802 val weighted: 0.905\n",
      "epoch: 1, batch: 200, train loss: 0.257, train macro: 0.898, train micro: 0.907, train sample: 0.804, train weighted 0.908, val loss: 0.259, val macro: 0.897, val micro: 0.906 val sample: 0.802 val weighted: 0.907\n",
      "epoch: 1, batch: 300, train loss: 0.256, train macro: 0.898, train micro: 0.907, train sample: 0.802, train weighted 0.907, val loss: 0.259, val macro: 0.893, val micro: 0.903 val sample: 0.806 val weighted: 0.904\n",
      "epoch: 1, batch: 400, train loss: 0.258, train macro: 0.895, train micro: 0.905, train sample: 0.796, train weighted 0.906, val loss: 0.259, val macro: 0.899, val micro: 0.906 val sample: 0.807 val weighted: 0.908\n",
      "epoch: 1, batch: 500, train loss: 0.254, train macro: 0.896, train micro: 0.906, train sample: 0.804, train weighted 0.907, val loss: 0.257, val macro: 0.897, val micro: 0.906 val sample: 0.810 val weighted: 0.907\n",
      "epoch: 2, batch: 100, train loss: 0.259, train macro: 0.894, train micro: 0.904, train sample: 0.800, train weighted 0.905, val loss: 0.258, val macro: 0.898, val micro: 0.907 val sample: 0.814 val weighted: 0.908\n",
      "epoch: 2, batch: 200, train loss: 0.255, train macro: 0.897, train micro: 0.907, train sample: 0.804, train weighted 0.908, val loss: 0.258, val macro: 0.896, val micro: 0.904 val sample: 0.815 val weighted: 0.906\n",
      "epoch: 2, batch: 300, train loss: 0.256, train macro: 0.895, train micro: 0.905, train sample: 0.798, train weighted 0.905, val loss: 0.258, val macro: 0.894, val micro: 0.904 val sample: 0.783 val weighted: 0.904\n",
      "epoch: 2, batch: 400, train loss: 0.250, train macro: 0.899, train micro: 0.908, train sample: 0.803, train weighted 0.909, val loss: 0.259, val macro: 0.888, val micro: 0.901 val sample: 0.790 val weighted: 0.901\n",
      "epoch: 2, batch: 500, train loss: 0.250, train macro: 0.901, train micro: 0.910, train sample: 0.807, train weighted 0.910, val loss: 0.258, val macro: 0.898, val micro: 0.906 val sample: 0.814 val weighted: 0.907\n",
      "TEST 512\n",
      "Loss: 0.259\n",
      "Micro F1: 0.898\n",
      "Macro F1: 0.907\n",
      "Sample F1: 0.816\n",
      "Weighted F1: 0.908\n",
      "Time: 1.272\n",
      "TRAIN 1024\n",
      "epoch: 1, batch: 100, train loss: 0.231, train macro: 0.941, train micro: 0.943, train sample: 0.850, train weighted 0.944, val loss: 0.300, val macro: 0.894, val micro: 0.903 val sample: 0.787 val weighted: 0.902\n",
      "epoch: 1, batch: 200, train loss: 0.223, train macro: 0.944, train micro: 0.945, train sample: 0.854, train weighted 0.946, val loss: 0.313, val macro: 0.890, val micro: 0.899 val sample: 0.784 val weighted: 0.898\n",
      "epoch: 1, batch: 300, train loss: 0.225, train macro: 0.945, train micro: 0.946, train sample: 0.854, train weighted 0.946, val loss: 0.312, val macro: 0.891, val micro: 0.900 val sample: 0.777 val weighted: 0.899\n",
      "epoch: 1, batch: 400, train loss: 0.227, train macro: 0.943, train micro: 0.944, train sample: 0.848, train weighted 0.945, val loss: 0.307, val macro: 0.894, val micro: 0.903 val sample: 0.790 val weighted: 0.902\n",
      "epoch: 1, batch: 500, train loss: 0.220, train macro: 0.944, train micro: 0.945, train sample: 0.851, train weighted 0.946, val loss: 0.317, val macro: 0.889, val micro: 0.899 val sample: 0.787 val weighted: 0.898\n",
      "epoch: 1, batch: 600, train loss: 0.225, train macro: 0.943, train micro: 0.945, train sample: 0.859, train weighted 0.946, val loss: 0.314, val macro: 0.889, val micro: 0.898 val sample: 0.792 val weighted: 0.897\n",
      "epoch: 2, batch: 100, train loss: 0.224, train macro: 0.943, train micro: 0.945, train sample: 0.854, train weighted 0.945, val loss: 0.317, val macro: 0.889, val micro: 0.898 val sample: 0.784 val weighted: 0.897\n",
      "epoch: 2, batch: 200, train loss: 0.220, train macro: 0.945, train micro: 0.947, train sample: 0.851, train weighted 0.947, val loss: 0.318, val macro: 0.891, val micro: 0.900 val sample: 0.778 val weighted: 0.899\n",
      "epoch: 2, batch: 300, train loss: 0.226, train macro: 0.942, train micro: 0.944, train sample: 0.848, train weighted 0.944, val loss: 0.311, val macro: 0.890, val micro: 0.900 val sample: 0.779 val weighted: 0.899\n",
      "epoch: 2, batch: 400, train loss: 0.218, train macro: 0.945, train micro: 0.946, train sample: 0.855, train weighted 0.947, val loss: 0.323, val macro: 0.890, val micro: 0.898 val sample: 0.779 val weighted: 0.898\n",
      "epoch: 2, batch: 500, train loss: 0.225, train macro: 0.944, train micro: 0.946, train sample: 0.854, train weighted 0.946, val loss: 0.317, val macro: 0.890, val micro: 0.898 val sample: 0.775 val weighted: 0.898\n",
      "epoch: 2, batch: 600, train loss: 0.220, train macro: 0.944, train micro: 0.945, train sample: 0.851, train weighted 0.946, val loss: 0.319, val macro: 0.892, val micro: 0.900 val sample: 0.785 val weighted: 0.900\n",
      "TEST 1024\n",
      "Loss: 0.227\n",
      "Micro F1: 0.943\n",
      "Macro F1: 0.944\n",
      "Sample F1: 0.863\n",
      "Weighted F1: 0.945\n",
      "Time: 1.717\n",
      "TRAIN 2048\n",
      "epoch: 1, batch: 100, train loss: 0.177, train macro: 0.941, train micro: 0.945, train sample: 0.856, train weighted 0.946, val loss: 0.168, val macro: 0.943, val micro: 0.947 val sample: 0.854 val weighted: 0.948\n",
      "epoch: 1, batch: 200, train loss: 0.174, train macro: 0.941, train micro: 0.946, train sample: 0.854, train weighted 0.947, val loss: 0.168, val macro: 0.942, val micro: 0.947 val sample: 0.841 val weighted: 0.948\n",
      "epoch: 1, batch: 300, train loss: 0.175, train macro: 0.939, train micro: 0.944, train sample: 0.848, train weighted 0.945, val loss: 0.167, val macro: 0.944, val micro: 0.948 val sample: 0.862 val weighted: 0.949\n",
      "epoch: 1, batch: 400, train loss: 0.169, train macro: 0.942, train micro: 0.946, train sample: 0.855, train weighted 0.947, val loss: 0.166, val macro: 0.944, val micro: 0.948 val sample: 0.850 val weighted: 0.949\n",
      "epoch: 1, batch: 500, train loss: 0.168, train macro: 0.944, train micro: 0.948, train sample: 0.857, train weighted 0.949, val loss: 0.167, val macro: 0.944, val micro: 0.948 val sample: 0.859 val weighted: 0.949\n",
      "epoch: 2, batch: 100, train loss: 0.172, train macro: 0.941, train micro: 0.946, train sample: 0.854, train weighted 0.947, val loss: 0.168, val macro: 0.943, val micro: 0.948 val sample: 0.863 val weighted: 0.949\n",
      "epoch: 2, batch: 200, train loss: 0.174, train macro: 0.941, train micro: 0.945, train sample: 0.854, train weighted 0.946, val loss: 0.166, val macro: 0.944, val micro: 0.948 val sample: 0.852 val weighted: 0.949\n",
      "epoch: 2, batch: 300, train loss: 0.172, train macro: 0.943, train micro: 0.946, train sample: 0.853, train weighted 0.947, val loss: 0.167, val macro: 0.943, val micro: 0.948 val sample: 0.852 val weighted: 0.949\n",
      "epoch: 2, batch: 400, train loss: 0.167, train macro: 0.945, train micro: 0.949, train sample: 0.856, train weighted 0.949, val loss: 0.169, val macro: 0.942, val micro: 0.946 val sample: 0.841 val weighted: 0.947\n",
      "epoch: 2, batch: 500, train loss: 0.168, train macro: 0.943, train micro: 0.947, train sample: 0.857, train weighted 0.948, val loss: 0.168, val macro: 0.943, val micro: 0.947 val sample: 0.847 val weighted: 0.948\n",
      "TEST 2048\n",
      "Loss: 0.170\n",
      "Micro F1: 0.941\n",
      "Macro F1: 0.946\n",
      "Sample F1: 0.846\n",
      "Weighted F1: 0.947\n",
      "Time: 1.740\n"
     ]
    }
   ],
   "source": [
    "for input in [\"512\", \"1024\", \"2048\"]:\n",
    "    match input:\n",
    "        case \"512\":\n",
    "            train_loader = train_loader_512\n",
    "            test_loader = test_loader_512\n",
    "            val_loader = val_loader_512\n",
    "            input_size = 32\n",
    "        case \"1024\":\n",
    "            train_loader = train_loader_1024\n",
    "            test_loader = test_loader_1024\n",
    "            input_size = 64\n",
    "        case \"2048\":\n",
    "            train_loader = train_loader_2048\n",
    "            test_loader = test_loader_2048\n",
    "            val_loader = val_loader_2048\n",
    "            input_size = 128\n",
    "        case \"4096\":\n",
    "            train_loader = train_loader_4096\n",
    "            test_loader = test_loader_4096\n",
    "            val_loader = val_loader_4096\n",
    "            input_size = 256\n",
    "\n",
    "    print(\"TRAIN \" + input)\n",
    "\n",
    "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "\n",
    "    train_metrics, val_metrics = train(transformer, criterion, optimizer, train_loader, val_loader, 2, threshold, device = device)\n",
    "    \n",
    "    print(\"TEST \" + input)\n",
    "\n",
    "    test_metrics = test(transformer, criterion, test_loader, threshold, device = device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Trained Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = 'EncoderResults/'\n",
    "tests1 = ['1encoder/', '2encoder/', '3encoder/', '4encoder/', '5encoder/', '6encoder/', '7encoder/', '8encoder/']\n",
    "\n",
    "path2 = 'HeadsResults/'\n",
    "tests2 = ['1head/', '2head/', '4head/', '6head/', '8head/', '12head/', '16head/', '20head/', '24head/']\n",
    "\n",
    "path3 = 'EmbeddingsResults/'\n",
    "tests3 = ['144emsize/', '192emsize/', '240emsize/', '288emsize/', '336emsize/', '384emsize/', '432emsize/', '480emsize/', '528emsize/']\n",
    "\n",
    "visualize_exeperiment(path3, tests3, 'Macro F1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"temp/model.pt\")\n",
    "data = pd.read_csv(\"Data/dataset_512.csv\", dtype = str)\n",
    "dataset = QueueDataset(data)\n",
    "data_loader = DataLoader(dataset, batch_size = 128, shuffle = True)\n",
    "\n",
    "criterion = nn.BCELoss().to(device)\n",
    "device = 'cuda'\n",
    "\n",
    "test(model, criterion, data_loader, threshold, device = device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

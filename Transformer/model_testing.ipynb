{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model import *\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the data\n",
    "split_ratio = 0.8\n",
    "val_ratio = 0.2\n",
    "data = pd.read_csv(\"Data/dataset_512.csv\", dtype = str)\n",
    "train_df = data.sample(frac = split_ratio)\n",
    "test_df = data.drop(train_df.index)\n",
    "val_df = train_df.sample(frac = val_ratio)\n",
    "train_df = train_df.drop(val_df.index)\n",
    "\n",
    "train_dataset = QueueDataset(train_df)\n",
    "test_dataset = QueueDataset(test_df)\n",
    "val_dataset = QueueDataset(val_df)\n",
    "\n",
    "#initialize the data loader \n",
    "train_loader_512 = DataLoader(train_dataset, batch_size = 128, shuffle = True)\n",
    "test_loader_512 = DataLoader(test_dataset, batch_size = 128, shuffle = True)\n",
    "val_loader_512 = DataLoader(val_dataset, batch_size = 128, shuffle = True)\n",
    "\n",
    "data = pd.read_csv(\"Data/dataset_1024.csv\", dtype = str)\n",
    "train_df = data.sample(frac = split_ratio)\n",
    "test_df = data.drop(train_df.index)\n",
    "val_df = train_df.sample(frac = val_ratio)\n",
    "train_df = train_df.drop(val_df.index)\n",
    "\n",
    "train_dataset = QueueDataset(train_df)\n",
    "test_dataset = QueueDataset(test_df)\n",
    "val_dataset = QueueDataset(val_df)\n",
    "\n",
    "train_loader_1024 = DataLoader(train_dataset, batch_size = 128, shuffle = True)\n",
    "test_loader_1024 = DataLoader(test_dataset, batch_size = 128, shuffle = True)\n",
    "val_loader_1024 = DataLoader(val_dataset, batch_size = 128, shuffle = True)\n",
    "\n",
    "data = pd.read_csv(\"Data/dataset_2048.csv\", dtype = str)\n",
    "train_df = data.sample(frac = split_ratio)\n",
    "test_df = data.drop(train_df.index)\n",
    "val_df = train_df.sample(frac = val_ratio)\n",
    "train_df = train_df.drop(val_df.index)\n",
    "\n",
    "train_dataset = QueueDataset(train_df)\n",
    "test_dataset = QueueDataset(test_df)\n",
    "val_dataset = QueueDataset(val_df)\n",
    "\n",
    "train_loader_2048 = DataLoader(train_dataset, batch_size = 128, shuffle = True)\n",
    "test_loader_2048 = DataLoader(test_dataset, batch_size = 128, shuffle = True)\n",
    "val_loader_2048 = DataLoader(val_dataset, batch_size = 128, shuffle = True)\n",
    "\n",
    "# data = pd.read_csv(\"Data/dataset_4096.csv\", dtype = str)\n",
    "# train_df = data.sample(frac = split_ratio)\n",
    "# test_df = data.drop(train_df.index)\n",
    "# val_df = train_df.sample(frac = val_ratio)\n",
    "# train_df = train_df.drop(val_df.index)\n",
    "\n",
    "# train_dataset = QueueDataset(train_df)\n",
    "# test_dataset = QueueDataset(test_df)\n",
    "# val_dataset = QueueDataset(val_df)\n",
    "\n",
    "# train_loader_4096 = DataLoader(train_dataset, batch_size = 128, shuffle = True)\n",
    "# test_loader_4096 = DataLoader(test_dataset, batch_size = 128, shuffle = True)\n",
    "# val_loader_4096 = DataLoader(val_dataset, batch_size = 128, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model hyperparameters \n",
    "ntokens = 65536  # size of vocabulary\n",
    "emsize = 240  # embedding dimension\n",
    "d_hid = 240  # dimension of the feedforward network model in ``nn.TransformerEncoder``\n",
    "nlayers = 3  # number of ``nn.TransformerEncoderLayer`` in ``nn.TransformerEncoder``\n",
    "nhead = 8 # number of heads in ``nn.MultiheadAttention``\n",
    "dropout = 0.2  # dropout probability\n",
    "threshold = 0.5\n",
    "device = \"cpu\"\n",
    "torch.cuda.empty_cache() if torch.cuda.is_available() else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN 2048\n",
      "epoch: 1, batch: 100, train loss: 35.764, train macro: 0.546, train micro: 0.711, train sample: 0.647, train weighted 0.641, val loss: 36.566, val macro: 0.542, val micro: 0.708 val sample: 0.643 val weighted: 0.639\n",
      "epoch: 1, batch: 200, train loss: 36.196, train macro: 0.547, train micro: 0.713, train sample: 0.650, train weighted 0.643, val loss: 36.566, val macro: 0.542, val micro: 0.708 val sample: 0.643 val weighted: 0.639\n",
      "epoch: 1, batch: 300, train loss: 36.612, train macro: 0.544, train micro: 0.708, train sample: 0.644, train weighted 0.638, val loss: 36.566, val macro: 0.542, val micro: 0.708 val sample: 0.643 val weighted: 0.639\n",
      "epoch: 1, batch: 400, train loss: 36.485, train macro: 0.543, train micro: 0.708, train sample: 0.644, train weighted 0.640, val loss: 36.566, val macro: 0.542, val micro: 0.708 val sample: 0.643 val weighted: 0.639\n",
      "epoch: 1, batch: 500, train loss: 36.796, train macro: 0.541, train micro: 0.705, train sample: 0.641, train weighted 0.636, val loss: 36.565, val macro: 0.542, val micro: 0.708 val sample: 0.643 val weighted: 0.639\n",
      "epoch: 2, batch: 100, train loss: 36.653, train macro: 0.544, train micro: 0.708, train sample: 0.643, train weighted 0.638, val loss: 36.566, val macro: 0.542, val micro: 0.708 val sample: 0.643 val weighted: 0.639\n",
      "epoch: 2, batch: 200, train loss: 36.400, train macro: 0.545, train micro: 0.710, train sample: 0.646, train weighted 0.640, val loss: 36.566, val macro: 0.542, val micro: 0.708 val sample: 0.643 val weighted: 0.639\n",
      "epoch: 2, batch: 300, train loss: 36.413, train macro: 0.545, train micro: 0.710, train sample: 0.647, train weighted 0.640, val loss: 36.566, val macro: 0.542, val micro: 0.708 val sample: 0.643 val weighted: 0.639\n",
      "epoch: 2, batch: 400, train loss: 36.286, train macro: 0.545, train micro: 0.711, train sample: 0.647, train weighted 0.642, val loss: 36.566, val macro: 0.542, val micro: 0.708 val sample: 0.643 val weighted: 0.639\n",
      "epoch: 2, batch: 500, train loss: 36.531, train macro: 0.543, train micro: 0.708, train sample: 0.644, train weighted 0.640, val loss: 36.566, val macro: 0.542, val micro: 0.708 val sample: 0.643 val weighted: 0.639\n",
      "epoch: 3, batch: 100, train loss: 36.542, train macro: 0.544, train micro: 0.708, train sample: 0.644, train weighted 0.639, val loss: 36.566, val macro: 0.542, val micro: 0.708 val sample: 0.643 val weighted: 0.639\n",
      "epoch: 3, batch: 200, train loss: 36.469, train macro: 0.545, train micro: 0.710, train sample: 0.645, train weighted 0.640, val loss: 36.566, val macro: 0.542, val micro: 0.708 val sample: 0.643 val weighted: 0.639\n",
      "epoch: 3, batch: 300, train loss: 36.340, train macro: 0.544, train micro: 0.710, train sample: 0.647, train weighted 0.642, val loss: 36.566, val macro: 0.542, val micro: 0.708 val sample: 0.643 val weighted: 0.639\n",
      "epoch: 3, batch: 400, train loss: 36.425, train macro: 0.544, train micro: 0.709, train sample: 0.646, train weighted 0.641, val loss: 36.566, val macro: 0.542, val micro: 0.708 val sample: 0.643 val weighted: 0.639\n"
     ]
    }
   ],
   "source": [
    "test = \"EmbeddingsResults/\"\n",
    "test_types = [480, 528]\n",
    "\n",
    "for test_number in test_types:\n",
    "    emsize = test_number\n",
    "    d_hid = test_number\n",
    "    test_type = \"/\" + str(test_number) + \"emsize/\"\n",
    "\n",
    "    for averaging in [True, False]:\n",
    "        average = \"Averaging\" if averaging else \"NonAveraging\"\n",
    "        for input in [\"512\", \"1024\", \"2048\"]:\n",
    "            match input:\n",
    "                case \"512\":\n",
    "                    train_loader = train_loader_512\n",
    "                    test_loader = test_loader_512\n",
    "                    val_loader = val_loader_512\n",
    "                    path = test + average + test_type + input\n",
    "                    input_size = 32\n",
    "                case \"1024\":\n",
    "                    train_loader = train_loader_1024\n",
    "                    test_loader = test_loader_1024\n",
    "                    val_loader = val_loader_1024\n",
    "                    path = test + average + test_type + input\n",
    "                    input_size = 64\n",
    "                case \"2048\":\n",
    "                    train_loader = train_loader_2048\n",
    "                    test_loader = test_loader_2048\n",
    "                    val_loader = val_loader_2048\n",
    "                    path = test + average + test_type + input\n",
    "                    input_size = 128\n",
    "                # case \"4096\":\n",
    "                #     train_loader = train_loader_4096\n",
    "                #     test_loader = test_loader_4096\n",
    "                #     val_loader = val_loader_4096\n",
    "                #     path = test + average + test_type + input\n",
    "                #     input_size = 256\n",
    "\n",
    "            print(\"TRAIN \" + input)\n",
    "\n",
    "            torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "\n",
    "            transformer = RandomLM(ntokens, emsize, nhead, d_hid, nlayers, input_size, dropout, averaging).to(device)\n",
    "            criterion = nn.BCELoss().to(device)\n",
    "            optimizer = torch.optim.Adam(transformer.parameters())\n",
    "\n",
    "            train_metrics, val_metrics = train(transformer, criterion, optimizer, train_loader, val_loader, 3, threshold, device = device)\n",
    "            \n",
    "            print(\"TEST \" + input)\n",
    "\n",
    "            test_metrics = inference(transformer, criterion, test_loader, threshold, device = device)\n",
    "            model_save(transformer, path, train_metrics, val_metrics, test_metrics)\n",
    "\n",
    "    del transformer, criterion, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Trained Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"TrainedModels/240embeddings-3encoder-24heads-128tokensize\"\n",
    "\n",
    "with ZipFile(path + \".zip\", \"r\") as myzip:\n",
    "    myzip.extractall(\"temp/\")\n",
    "\n",
    "train_metrics = pd.read_csv(\"temp/train_metrics.csv\", index_col = 0)\n",
    "val_metrics = pd.read_csv(\"temp/val_metrics.csv\", index_col = 0)\n",
    "\n",
    "plot_metrics(train_metrics, val_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"temp/model.pt\")\n",
    "\n",
    "# data_loader = None #loader for the data\n",
    "# inference(model, criterion, test_loader, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.remove(\"temp/train_metrics.csv\")\n",
    "os.remove(\"temp/val_metrics.csv\")\n",
    "if (os.path.exists(\"temp/model.pth\")):\n",
    "    os.remove(\"temp/model.pth\")\n",
    "if (os.path.exists(\"temp/model.pt\")):\n",
    "    os.remove(\"temp/model.pt\")\n",
    "os.rmdir(\"temp\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Randomness_Testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

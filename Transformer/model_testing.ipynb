{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model import *\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "    \n",
    "#RNN model with LSTM which takes input and embedds it to a certain dimension and then passes it through the LSTM layer and then the output is passed through a fully connected layer to get the final output\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.device = 'cpu'\n",
    "        # self.embedding = nn.Embedding(65536, input_size)\n",
    "        # self.pe = PositionalEncoding(input_size)\n",
    "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout = 0.2)\n",
    "        self.fc = nn.Sequential(nn.Linear(hidden_size, num_classes), nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(self.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(self.device)\n",
    "        # x = self.embedding(x)\n",
    "        # x = self.pe(x)\n",
    "        x = torch.nn.functional.one_hot(x.to(torch.int64), num_classes=2).float()\n",
    "        out, _ = self.rnn(x, (h0, c0))\n",
    "        # out = out[:, -1, :]\n",
    "        out = torch.mean(out, 1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "transformer = RNN(input_size = 2, hidden_size = 1024, num_layers = 2, num_classes = 7).to('cpu')\n",
    "criterion = nn.BCELoss().to('cpu')\n",
    "optimizer = torch.optim.Adam(transformer.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the data\n",
    "load_lstm = False\n",
    "\n",
    "split_ratio = 0.8\n",
    "val_ratio = 0.2\n",
    "data = pd.read_csv(\"Data/dataset_512.csv\", dtype = str)\n",
    "train_df = data.sample(frac = split_ratio)\n",
    "test_df = data.drop(train_df.index)\n",
    "val_df = train_df.sample(frac = val_ratio)\n",
    "train_df = train_df.drop(val_df.index)\n",
    "\n",
    "train_dataset = QueueDataset_LSTM(train_df) if load_lstm else QueueDataset(train_df)\n",
    "test_dataset = QueueDataset_LSTM(test_df) if load_lstm else QueueDataset(test_df)\n",
    "val_dataset = QueueDataset_LSTM(val_df) if load_lstm else QueueDataset(val_df)\n",
    "\n",
    "#initialize the data loader \n",
    "train_loader_512 = DataLoader(train_dataset, batch_size = 128, shuffle = True)\n",
    "test_loader_512 = DataLoader(test_dataset, batch_size = 128, shuffle = True)\n",
    "val_loader_512 = DataLoader(val_dataset, batch_size = 128, shuffle = True)\n",
    "\n",
    "data = pd.read_csv(\"Data/dataset_1024.csv\", dtype = str)\n",
    "train_df = data.sample(frac = split_ratio)\n",
    "test_df = data.drop(train_df.index)\n",
    "val_df = train_df.sample(frac = val_ratio)\n",
    "train_df = train_df.drop(val_df.index)\n",
    "\n",
    "train_dataset = QueueDataset_LSTM(train_df) if load_lstm else QueueDataset(train_df)\n",
    "test_dataset = QueueDataset_LSTM(test_df) if load_lstm else QueueDataset(test_df)\n",
    "val_dataset = QueueDataset_LSTM(val_df) if load_lstm else QueueDataset(val_df)\n",
    "\n",
    "train_loader_1024 = DataLoader(train_dataset, batch_size = 128, shuffle = True)\n",
    "test_loader_1024 = DataLoader(test_dataset, batch_size = 128, shuffle = True)\n",
    "val_loader_1024 = DataLoader(val_dataset, batch_size = 128, shuffle = True)\n",
    "\n",
    "data = pd.read_csv(\"Data/dataset_2048.csv\", dtype = str)\n",
    "train_df = data.sample(frac = split_ratio)\n",
    "test_df = data.drop(train_df.index)\n",
    "val_df = train_df.sample(frac = val_ratio)\n",
    "train_df = train_df.drop(val_df.index)\n",
    "\n",
    "train_dataset = QueueDataset_LSTM(train_df) if load_lstm else QueueDataset(train_df)\n",
    "test_dataset = QueueDataset_LSTM(test_df) if load_lstm else QueueDataset(test_df)\n",
    "val_dataset = QueueDataset_LSTM(val_df) if load_lstm else QueueDataset(val_df)\n",
    "\n",
    "train_loader_2048 = DataLoader(train_dataset, batch_size = 128, shuffle = True)\n",
    "test_loader_2048 = DataLoader(test_dataset, batch_size = 128, shuffle = True)\n",
    "val_loader_2048 = DataLoader(val_dataset, batch_size = 128, shuffle = True)\n",
    "\n",
    "data = pd.read_csv(\"Data/dataset_4096.csv\", dtype = str)\n",
    "train_df = data.sample(frac = split_ratio)\n",
    "test_df = data.drop(train_df.index)\n",
    "val_df = train_df.sample(frac = val_ratio)\n",
    "train_df = train_df.drop(val_df.index)\n",
    "\n",
    "train_dataset = QueueDataset_LSTM(train_df) if load_lstm else QueueDataset(train_df)\n",
    "test_dataset = QueueDataset_LSTM(test_df) if load_lstm else QueueDataset(test_df)\n",
    "val_dataset = QueueDataset_LSTM(val_df) if load_lstm else QueueDataset(val_df)\n",
    "\n",
    "train_loader_4096 = DataLoader(train_dataset, batch_size = 128, shuffle = True)\n",
    "test_loader_4096 = DataLoader(test_dataset, batch_size = 128, shuffle = True)\n",
    "val_loader_4096 = DataLoader(val_dataset, batch_size = 128, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model hyperparameters \n",
    "ntokens = 65536  # size of vocabulary\n",
    "emsize = 192  # embedding dimension\n",
    "d_hid = 192  # dimension of the feedforward network model in ``nn.TransformerEncoder``\n",
    "nlayers = 1  # number of ``nn.TransformerEncoderLayer`` in ``nn.TransformerEncoder``\n",
    "nhead = 1 # number of heads in ``nn.MultiheadAttention``\n",
    "dropout = 0.05  # dropout probability\n",
    "threshold = 0.5\n",
    "input_size = 32\n",
    "device = \"cuda\"\n",
    "torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "transformer = RandomLM(ntokens, emsize, nhead, d_hid, nlayers, input_size, dropout, True).to(device)\n",
    "criterion = nn.BCELoss().to(device)\n",
    "optimizer = torch.optim.Adam(transformer.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"EncoderResults/\"\n",
    "test_types = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "for test_number in test_types:\n",
    "    emsize = test_number\n",
    "    d_hid = test_number\n",
    "    test_type = \"/\" + str(test_number) + \"encoder/\"\n",
    "\n",
    "    for averaging in [False, True]:\n",
    "        average = \"Averaging\" if averaging else \"NonAveraging\"\n",
    "        for input in [\"512\", \"1024\", \"2048\", \"4096\"]:\n",
    "            match input:\n",
    "                case \"512\":\n",
    "                    train_loader = train_loader_512\n",
    "                    test_loader = test_loader_512\n",
    "                    val_loader = val_loader_512\n",
    "                    path = test + average + test_type + input\n",
    "                    input_size = 32\n",
    "                case \"1024\":\n",
    "                    train_loader = train_loader_1024\n",
    "                    test_loader = test_loader_1024\n",
    "                    val_loader = val_loader_1024\n",
    "                    path = test + average + test_type + input\n",
    "                    input_size = 64\n",
    "                case \"2048\":\n",
    "                    train_loader = train_loader_2048\n",
    "                    test_loader = test_loader_2048\n",
    "                    val_loader = val_loader_2048\n",
    "                    path = test + average + test_type + input\n",
    "                    input_size = 128\n",
    "                case \"4096\":\n",
    "                    train_loader = train_loader_4096\n",
    "                    test_loader = test_loader_4096\n",
    "                    val_loader = val_loader_4096\n",
    "                    path = test + average + test_type + input\n",
    "                    input_size = 256\n",
    "\n",
    "            print(\"TRAIN \" + input)\n",
    "\n",
    "            torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "\n",
    "            transformer = RandomLM(ntokens, emsize, nhead, d_hid, nlayers, input_size, dropout, averaging).to(device)\n",
    "            criterion = nn.BCELoss().to(device)\n",
    "            optimizer = torch.optim.Adam(transformer.parameters())\n",
    "\n",
    "            train_metrics, val_metrics = train(transformer, criterion, optimizer, train_loader, val_loader, 3, threshold, device = device)\n",
    "            \n",
    "            print(\"TEST \" + input)\n",
    "\n",
    "            test_metrics = inference(transformer, criterion, test_loader, threshold, device = device)\n",
    "            model_save(transformer, path, train_metrics, val_metrics, test_metrics)\n",
    "\n",
    "    del transformer, criterion, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Trained Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = 'EncoderResults/'\n",
    "tests1 = ['1encoder/', '2encoder/', '3encoder/', '4encoder/', '5encoder/', '6encoder/', '7encoder/', '8encoder/']\n",
    "\n",
    "path2 = 'HeadsResults/'\n",
    "tests2 = ['1head/', '2head/', '4head/', '6head/', '8head/', '12head/', '16head/', '20head/', '24head/']\n",
    "\n",
    "path3 = 'EmbeddingsResults/'\n",
    "tests3 = ['144emsize/', '192emsize/', '240emsize/', '288emsize/', '336emsize/', '384emsize/', '432emsize/', '480emsize/', '528emsize/']\n",
    "\n",
    "visualize_exeperiment(path3, tests3, 'Macro F1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"temp/model.pt\")\n",
    "data = pd.read_csv(\"Data/dataset_512.csv\", dtype = str)\n",
    "dataset = QueueDataset(data)\n",
    "data_loader = DataLoader(dataset, batch_size = 128, shuffle = True)\n",
    "\n",
    "criterion = nn.BCELoss().to(device)\n",
    "device = 'cuda'\n",
    "\n",
    "inference(model, criterion, data_loader, threshold, device = device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Randomness_Testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
